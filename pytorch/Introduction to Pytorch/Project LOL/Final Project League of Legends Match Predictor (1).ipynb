{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" height=300 width=300 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: League of Legends Match Predictor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Installing required libraries:\n",
    "\n",
    "The following required libraries are not pre-installed in the Skills Network Labs environment. You will need to run the following cell to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction  \n",
    "\n",
    "League of Legends, a popular multiplayer online battle arena (MOBA) game, generates extensive data from matches, providing an excellent opportunity to apply machine learning techniques to real-world scenarios. Perform the following steps to build a logistic regression model aimed at predicting the outcomes of League of Legends matches.  \n",
    "\n",
    "Use the [league_of_legends_data_large.csv](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/rk7VDaPjMp1h5VXS-cUyMg/league-of-legends-data-large.csv) file to perform the tasks.  \n",
    "\n",
    "### Step 1: Data Loading and Preprocessing  \n",
    "\n",
    "#### Task 1: Load the League of Legends dataset and preprocess it for training.  \n",
    "\n",
    "Loading and preprocessing the dataset involves reading the data, splitting it into training and testing sets, and standardizing the features. You will utilize `pandas` for data manipulation, `train_test_split` from `sklearn` for data splitting, and `StandardScaler` for feature scaling.  \n",
    "\n",
    "Note: Please ensure all the required libraries are installed and imported.\n",
    "\n",
    "1 .Load the dataset:\n",
    "Use `pd.read_csv()` to load the dataset into a pandas DataFrame.</br>\n",
    "2. Split data into features and target: Separate win (target) and the remaining columns (features).</br>\n",
    "   X = data.drop('win', axis=1)</br>\n",
    "   y = data['win'] </br>\n",
    "3 .Split the Data into Training and Testing Sets:\n",
    "Use `train_test_split()` from `sklearn.model_selection` to divide the data. Set `test_size`=0.2 to allocate 20% for testing and 80% for training, and use `random_state`=42 to ensure reproducibility of the split.</br>\n",
    "4. Standardize the features:\n",
    "Use `StandardScaler()` from sklearn.preprocessing to scale the features.</br>\n",
    "5. Convert to PyTorch tensors:\n",
    "Use `torch.tensor()` to convert the data to PyTorch tensors.\n",
    "\n",
    "#### Exercise 1:  \n",
    "\n",
    "Write a code to load the dataset, split it into training and testing sets, standardize the features, and convert the data into PyTorch tensors for use in training a PyTorch model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>win</th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>assists</th>\n",
       "      <th>gold_earned</th>\n",
       "      <th>cs</th>\n",
       "      <th>wards_placed</th>\n",
       "      <th>wards_killed</th>\n",
       "      <th>damage_dealt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>17088</td>\n",
       "      <td>231</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>15367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>14865</td>\n",
       "      <td>259</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>38332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>15919</td>\n",
       "      <td>169</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>24642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11534</td>\n",
       "      <td>264</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>18926</td>\n",
       "      <td>124</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>40268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   win  kills  deaths  assists  gold_earned   cs  wards_placed  wards_killed  \\\n",
       "0    0     16       6       19        17088  231            11             7   \n",
       "1    1      8       8        5        14865  259            10             2   \n",
       "2    0      0      17       11        15919  169            14             5   \n",
       "3    0     19      11        1        11534  264            14             3   \n",
       "4    0     12       7        6        18926  124            15             7   \n",
       "\n",
       "   damage_dealt  \n",
       "0         15367  \n",
       "1         38332  \n",
       "2         24642  \n",
       "3         15789  \n",
       "4         40268  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing,model_selection\n",
    "import torch\n",
    "lol_data = pd.read_csv('league_of_legends_data_large.csv')\n",
    "lol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lol_data.drop(columns=['win'])\n",
    "y = lol_data['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "win\n",
       "1    510\n",
       "0    490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=.20,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,shuffle=True,batch_size=32)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test,y_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,shuffle=False,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Logistic Regression Model  \n",
    "\n",
    "#### Task 2: Implement a logistic regression model using PyTorch.  \n",
    "\n",
    "Defining the logistic regression model involves specifying the input dimensions, the forward pass using the sigmoid activation function, and initializing the model, loss function, and optimizer.  \n",
    "\n",
    "1 .Define the Logistic Regression Model:</br>\n",
    "  Create a class LogisticRegressionModel that inherits from torch.nn.Module.</br>\n",
    " - In the `__init__()` method, define a linear layer (nn.Linear) to implement the logistic regression model.</br>\n",
    "- The `forward()` method should apply the sigmoid activation function to the output of the linear layer.</br>\n",
    "\n",
    "2.Initialize the Model, Loss Function, and Optimizer:</br>\n",
    "- Set input_dim: Use `X_train.shape[1]` to get the number of features from the training data (X_train).</br>\n",
    "- Initialize the model: Create an instance of the LogisticRegressionModel class  (e.g., `model = LogisticRegressionModel()`)while passing input_dim as a parameter</br>\n",
    "- Loss Function: Use `BCELoss()` from torch.nn (Binary Cross-Entropy Loss).</br>\n",
    "- Optimizer: Initialize the optimizer using `optim.SGD()` with a learning rate of 0.01</br>\n",
    "\n",
    "#### Exercise 2:  \n",
    "\n",
    "Define the logistic regression model using PyTorch, specifying the input dimensions and the forward pass. Initialize the model, loss function, and optimizer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,optim\n",
    "\n",
    "class Logistic_Regression(nn.Module):\n",
    "    def __init__(self,input_units=8):\n",
    "        super(Logistic_Regression,self).__init__()\n",
    "        self.linear = nn.Linear(in_features=input_units,out_features=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Training  \n",
    "\n",
    "#### Task 3: Train the logistic regression model on the dataset.  \n",
    "\n",
    "The training loop will run for a specified number of epochs. In each epoch, the model makes predictions, calculates the loss, performs backpropagation, and updates the model parameters.\n",
    "\n",
    "1. Set Number of Epochs:  \n",
    "   - Define the number of epochs for training to 1000.\n",
    "\n",
    "2. Training Loop:  \n",
    "   For each epoch:\n",
    "   - Set the model to training mode using `model.train()`.\n",
    "   - Zero the gradients using `optimizer.zero_grad()`.\n",
    "   - Pass the training data (`X_train`) through the model to get the predictions (`outputs`).\n",
    "   - Calculate the loss using the defined loss function (`criterion`).\n",
    "   - Perform backpropagation with `loss.backward()`.\n",
    "   - Update the model's weights using `optimizer.step()`.\n",
    "\n",
    "3. Print Loss Every 100 Epochs:  \n",
    "   - After every 100 epochs, print the current epoch number and the loss value.\n",
    "\n",
    "4. Model Evaluation:  \n",
    "   - Set the model to evaluation mode using `model.eval()`.\n",
    "   - Use `torch.no_grad()` to ensure no gradients are calculated during evaluation.\n",
    "   - Get predictions on both the training set (`X_train`) and the test set (`X_test`).\n",
    "\n",
    "5. Calculate Accuracy:  \n",
    "   - For both the training and test datasets, compute the accuracy by comparing the predicted values with the true values (`y_train`, `y_test`).\n",
    "   - Use a threshold of 0.5 for classification\n",
    "   \n",
    "6. Print Accuracy:  \n",
    "   - Print the training and test accuracies after the evaluation is complete.\n",
    "\n",
    "#### Exercise 3:  \n",
    "\n",
    "Write the code to train the logistic regression model on the dataset. Implement the training loop, making predictions, calculating the loss, performing backpropagation, and updating model parameters. Evaluate the model's accuracy on training and testing sets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000] Train Accuracy : 0.51875 Train Loss: 0.6906294536590576 Test Accuracy: 0.54 Test Loss: 0.6831273436546326\n",
      "Epoch [200/1000] Train Accuracy : 0.52375 Train Loss: 0.690593626499176 Test Accuracy: 0.54 Test Loss: 0.6829930925369263\n",
      "Epoch [300/1000] Train Accuracy : 0.52125 Train Loss: 0.6905676031112671 Test Accuracy: 0.54 Test Loss: 0.682904646396637\n",
      "Epoch [400/1000] Train Accuracy : 0.5225 Train Loss: 0.6906537318229675 Test Accuracy: 0.535 Test Loss: 0.6830184316635132\n",
      "Epoch [500/1000] Train Accuracy : 0.5225 Train Loss: 0.6906656885147094 Test Accuracy: 0.54 Test Loss: 0.68296315908432\n",
      "Epoch [600/1000] Train Accuracy : 0.52 Train Loss: 0.6906295394897461 Test Accuracy: 0.54 Test Loss: 0.6829714512825013\n",
      "Epoch [700/1000] Train Accuracy : 0.52875 Train Loss: 0.6906583189964295 Test Accuracy: 0.54 Test Loss: 0.6829656362533569\n",
      "Epoch [800/1000] Train Accuracy : 0.5225 Train Loss: 0.6906256318092346 Test Accuracy: 0.535 Test Loss: 0.6829602456092835\n",
      "Epoch [900/1000] Train Accuracy : 0.5225 Train Loss: 0.6906424283981323 Test Accuracy: 0.535 Test Loss: 0.6829625296592713\n",
      "Epoch [1000/1000] Train Accuracy : 0.5225 Train Loss: 0.6906641793251037 Test Accuracy: 0.54 Test Loss: 0.6830295372009277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_features = X_train.shape[1]\n",
    "model = Logistic_Regression(n_features)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "epochs = 1000\n",
    "TRAIN_LOSS = []\n",
    "TRAIN_ACC = []\n",
    "\n",
    "TEST_LOSS = []\n",
    "TEST_ACC = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_total = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x).squeeze()\n",
    "        loss = criterion(yhat,y)\n",
    "        #compute metrics\n",
    "        train_loss += loss.item() * y.size(0)\n",
    "        train_acc += ((yhat >.5).float() == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_total = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            yhat = model(x).squeeze()\n",
    "            loss = criterion(yhat,y)\n",
    "            #Compute metrics\n",
    "            test_loss += loss.item() * y.size(0)\n",
    "            test_acc += ((yhat >.5).float() == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "\n",
    "    #ASSIGN METRIC VALUES TO THE EPOCH\n",
    "\n",
    "    epoch_train_loss = train_loss/train_total\n",
    "    epoch_train_acc =  train_acc/train_total\n",
    "    epoch_test_loss = test_loss/test_total\n",
    "    epoch_test_acc =  test_acc/test_total\n",
    "\n",
    "    TRAIN_LOSS.append(epoch_train_loss)\n",
    "    TRAIN_ACC.append(epoch_train_acc)\n",
    "    TEST_LOSS.append(epoch_test_loss)\n",
    "    TEST_ACC.append(epoch_test_acc)\n",
    "    \n",
    "    \n",
    "            \n",
    "    if (epoch +1) % 100==0:\n",
    "         print(f'Epoch [{epoch+1}/{epochs}] Train Accuracy : {epoch_train_acc} Train Loss: {epoch_train_loss} Test Accuracy: {epoch_test_acc} Test Loss: {epoch_test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Optimization and Evaluation  \n",
    "\n",
    "#### Task 4: Implement optimization techniques and evaluate the model's performance.  \n",
    "\n",
    "Optimization techniques such as L2 regularization (Ridge Regression) help in preventing overfitting. The model is retrained with these optimizations, and its performance is evaluated on both training and testing sets. \n",
    "\n",
    "**Weight Decay** :In the context of machine learning and specifically in optimization algorithms, weight_decay is a parameter used to apply L2 regularization to the model's parameters (weights). It helps prevent the model from overfitting by penalizing large weight values, thereby encouraging the model to find simpler solutions.To use L2 regularization, you need to modify the optimizer by setting the weight_decay parameter. The weight_decay parameter in the optimizer adds the L2 regularization term during training.\n",
    "For example, when you initialize the optimizer with optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01), the weight_decay=0.01 term applies L2 regularization with a strength of 0.01.\n",
    "\n",
    "1. Set Up the Optimizer with L2 Regularization:\n",
    "   - Modify the optimizer to include `weight_decay` for L2 regularization.\n",
    "   - Example:\n",
    "     ```python\n",
    "     optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "     ```\n",
    "2. Train the Model with L2 Regularization:\n",
    "    - Follow the same steps as before but use the updated optimizer with regularization during training.\n",
    "    - Use epochs=1000\n",
    "   \n",
    "3. Evaluate the Optimized Model:\n",
    "   - After training, evaluate the model on both the training and test datasets.\n",
    "   - Compute the accuracy for both sets by comparing the model's predictions to the true labels (`y_train` and `y_test`).\n",
    "\n",
    "4. Calculate and Print the Accuracy:\n",
    "   - Use a threshold of 0.5 to determine whether the model's predictions are class 0 or class 1.\n",
    "   - Print the training accuracy and test accuracy  after evaluation.\n",
    "\n",
    "\n",
    "#### Exercise 4:  \n",
    "\n",
    "Implement optimization techniques like L2 regularization and retrain the model. Evaluate the performance of the optimized model on both training and testing sets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000] Train Accuracy : 0.52 Train Loss: 0.6906518816947937 Test Accuracy: 0.545 Test Loss: 0.6834270691871643\n",
      "Epoch [200/1000] Train Accuracy : 0.52125 Train Loss: 0.6906864356994629 Test Accuracy: 0.535 Test Loss: 0.6833286309242248\n",
      "Epoch [300/1000] Train Accuracy : 0.52375 Train Loss: 0.6906531190872193 Test Accuracy: 0.535 Test Loss: 0.6833311653137207\n",
      "Epoch [400/1000] Train Accuracy : 0.51875 Train Loss: 0.6906265163421631 Test Accuracy: 0.545 Test Loss: 0.6832252597808838\n",
      "Epoch [500/1000] Train Accuracy : 0.52375 Train Loss: 0.6906306099891663 Test Accuracy: 0.545 Test Loss: 0.6832296943664551\n",
      "Epoch [600/1000] Train Accuracy : 0.51875 Train Loss: 0.690634605884552 Test Accuracy: 0.535 Test Loss: 0.6832969498634338\n",
      "Epoch [700/1000] Train Accuracy : 0.52 Train Loss: 0.6906218218803406 Test Accuracy: 0.535 Test Loss: 0.6832979202270508\n",
      "Epoch [800/1000] Train Accuracy : 0.52125 Train Loss: 0.6906558179855347 Test Accuracy: 0.54 Test Loss: 0.6832813000679017\n",
      "Epoch [900/1000] Train Accuracy : 0.5225 Train Loss: 0.6906163692474365 Test Accuracy: 0.535 Test Loss: 0.6833082461357116\n",
      "Epoch [1000/1000] Train Accuracy : 0.52125 Train Loss: 0.6906562423706055 Test Accuracy: 0.545 Test Loss: 0.6832730746269227\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_features = X_train.shape[1]\n",
    "model = Logistic_Regression(n_features)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01,weight_decay=.01)\n",
    "epochs = 1000\n",
    "TRAIN_LOSS = []\n",
    "TRAIN_ACC = []\n",
    "\n",
    "TEST_LOSS = []\n",
    "TEST_ACC = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_total = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x).squeeze()\n",
    "        loss = criterion(yhat,y)\n",
    "        #compute metrics\n",
    "        train_loss += loss.item() * y.size(0)\n",
    "        train_acc += ((yhat >.5).float() == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_total = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            yhat = model(x).squeeze()\n",
    "            loss = criterion(yhat,y)\n",
    "            #Compute metrics\n",
    "            test_loss += loss.item() * y.size(0)\n",
    "            test_acc += ((yhat >.5).float() == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "\n",
    "    #ASSIGN METRIC VALUES TO THE EPOCH\n",
    "\n",
    "    epoch_train_loss = train_loss/train_total\n",
    "    epoch_train_acc =  train_acc/train_total\n",
    "    epoch_test_loss = test_loss/test_total\n",
    "    epoch_test_acc =  test_acc/test_total\n",
    "\n",
    "    TRAIN_LOSS.append(epoch_train_loss)\n",
    "    TRAIN_ACC.append(epoch_train_acc)\n",
    "    TEST_LOSS.append(epoch_test_loss)\n",
    "    TEST_ACC.append(epoch_test_acc)\n",
    "    \n",
    "    \n",
    "            \n",
    "    if (epoch +1) % 100==0:\n",
    "         print(f'Epoch [{epoch+1}/{epochs}] Train Accuracy : {epoch_train_acc} Train Loss: {epoch_train_loss} Test Accuracy: {epoch_test_acc} Test Loss: {epoch_test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualization and Interpretation  \n",
    "\n",
    "Visualization tools like confusion matrices and ROC curves provide insights into the model's performance. The confusion matrix helps in understanding the classification accuracy, while the ROC curve illustrates the trade-off between sensitivity and specificity.\n",
    "\n",
    "Confusion Matrix : A Confusion Matrix is a fundamental tool used in classification problems to evaluate the performance of a model. It provides a matrix showing the number of correct and incorrect predictions made by the model, categorized by the actual and predicted classes.\n",
    "Where \n",
    "-  True Positive (TP): Correctly predicted positive class (class 1).\n",
    "- True Negative (TN): Correctly predicted negative class (class 0).\n",
    "- False Positive (FP): Incorrectly predicted as positive (class 1), but the actual class is negative (class 0). This is also called a Type I error.\n",
    "- False Negative (FN): Incorrectly predicted as negative (class 0), but the actual class is positive (class 1). This is also called a Type II error. \n",
    "\n",
    "ROC Curve (Receiver Operating Characteristic Curve):\n",
    "The ROC Curve is a graphical representation used to evaluate the performance of a binary classification model across all classification thresholds. It plots two metrics:\n",
    "- True Positive Rate (TPR) or Recall (Sensitivity)-It is the proportion of actual positive instances (class 1) that were correctly classified as positive by the model.\n",
    "- False Positive Rate (FPR)-It is the proportion of actual negative instances (class 0) that were incorrectly classified as positive by the model.\n",
    "  \n",
    "AUC: \n",
    "AUC stands for Area Under the Curve and is a performance metric used to evaluate the quality of a binary classification model. Specifically, it refers to the area under the ROC curve (Receiver Operating Characteristic curve), which plots the True Positive Rate (TPR) versus the False Positive Rate (FPR) for different threshold values.\n",
    "\n",
    "Classification Report:\n",
    "A Classification Report is a summary of various classification metrics, which are useful for evaluating the performance of a classifier on the given dataset.\n",
    "\n",
    "#### Exercise 5:  \n",
    "\n",
    "Write code to visualize the model's performance using confusion matrices and ROC curves. Generate classification reports to evaluate precision, recall, and F1-score. Retrain the model with L2 regularization and evaluate the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        yhat = model(x)\n",
    "        _, predicted = torch.max(yhat, 1)\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(y.numpy())\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98,   0],\n",
       "       [102,   0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      1.00      0.66        98\n",
      "         1.0       0.00      0.00      0.00       102\n",
      "\n",
      "    accuracy                           0.49       200\n",
      "   macro avg       0.24      0.50      0.33       200\n",
      "weighted avg       0.24      0.49      0.32       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels,all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the Hint.\n",
    "<!-- \n",
    "\n",
    "#Change the name of variables as per your code\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import itertools\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "#Change the variable names as used in your code\n",
    "y_pred_test_labels = (y_pred_test > 0.5).float()\n",
    "cm = confusion_matrix(y_test, y_pred_test_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = range(2)\n",
    "plt.xticks(tick_marks, ['Loss', 'Win'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Loss', 'Win'])\n",
    "\n",
    "thresh = cm.max() / 2\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_labels, target_names=['Loss', 'Win']))\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Model Saving and Loading  \n",
    "\n",
    "#### Task 6: Save and load the trained model.  \n",
    "\n",
    "This task demonstrates the techniques to persist a trained model using `torch.save` and reload it using `torch.load`. Evaluating the loaded model ensures that it retains its performance, making it practical for deployment in real-world applications.  \n",
    "\n",
    "1. Saving the Model:\n",
    "- Save the model's learned weights and biases using torch.save().( e.g. , torch.save(model.state_dict(), 'your_model_name.pth'))\n",
    "- Saving only the state dictionary (model parameters) is preferred because it’s more flexible and efficient than saving the entire model object.\n",
    "\n",
    "2. Loading the Model:\n",
    "- Create a new model instance (e.g., `model = LogisticRegressionModel()`) and load the saved parameters. ( e.g. , `model.load_state_dict(torch.load('your_model_name.pth'))`)`.\n",
    "\n",
    "3. Evaluating the Loaded Model:\n",
    "   - After loading, set the model to evaluation mode by calling `model.eval()\n",
    "   - After loading the model, evaluate it again on the test dataset to make sure it performs similarly to when it was first trained..Now evaluate it on the test data.\n",
    "   - Use `torch.no_grad()` to ensure that no gradients are computed.\n",
    "\n",
    "#### Exercise 6:  \n",
    "\n",
    "Write code to save the trained model and reload it. Ensure the loaded model performs consistently by evaluating it on the test dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# Save the model\n",
    "\n",
    "\n",
    "# Load the model\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the loaded model is in evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the loaded model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Hyperparameter Tuning  \n",
    "\n",
    "#### Task 7: Perform hyperparameter tuning to find the best learning rate.  \n",
    "\n",
    "By testing different learning rates, you will identify the optimal rate that provides the best test accuracy. This fine-tuning is crucial for enhancing model performance . \n",
    "1. Define Learning Rates:\n",
    "   - Choose these learning rates to test ,[0.01, 0.05, 0.1]\n",
    "\n",
    "2. Reinitialize the Model for Each Learning Rate:\n",
    "  - For each learning rate, you’ll need to reinitialize the model and optimizer e.g.(`torch.optim.SGD(model.parameters(), lr=lr)`).\n",
    "   - Each new learning rate requires reinitializing the model since the optimizer and its parameters are linked to the learning rate.\n",
    "\n",
    "3. Train the Model for Each Learning Rate:\n",
    "  - Train the model for a fixed number of epochs (e.g., 50 or 100 epochs) for each learning rate, and compute the accuracy on the test set.\n",
    "  - Track the test accuracy for each learning rate and identify which one yields the best performance.\n",
    "\n",
    "4. Evaluate and Compare:\n",
    "  - After training with each learning rate, compare the test accuracy for each configuration.\n",
    "   - Report the learning rate that gives the highest test accuracy\n",
    "\n",
    "#### Exercise 7:  \n",
    "\n",
    "Perform hyperparameter tuning to find the best learning rate. Retrain the model for each learning rate and evaluate its performance to identify the optimal rate.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Feature Importance  \n",
    "\n",
    "#### Task 8: Evaluate feature importance to understand the impact of each feature on the prediction.  \n",
    "\n",
    "The code to evaluate feature importance to understand the impact of each feature on the prediction.\n",
    "\n",
    " 1.Extracting Model Weights:\n",
    "  - The weights of the logistic regression model represent the importance of each feature in making predictions. These weights are stored in the model's linear layer (`model.linear.weight`).\n",
    " - You can extract the weights using `model.linear.weight.data.numpy()` and flatten the resulting tensor to get a 1D array of feature importances.\n",
    "\n",
    "2.Creating a DataFrame:\n",
    " - Create a pandas DataFrame with two columns: one for the feature names and the other for their corresponding importance values (i.e., the learned weights).\n",
    " - Ensure the features are aligned with their names in your dataset (e.g., `X_train.columns).\n",
    "\n",
    "3. Sorting and Plotting Feature Importance:\n",
    "  - Sort the features based on the absolute value of their importance (weights) to identify the most impactful features.\n",
    "  - Use a bar plot (via `matplotlib`) to visualize the sorted feature importances, with the feature names on the y-axis and importance values on the x-axis.\n",
    "\n",
    "4. Interpreting the Results:\n",
    "  - Larger absolute weights indicate more influential features. Positive weights suggest a positive correlation with the outcome (likely to predict the positive class), while negative weights suggest the opposite.\n",
    "\n",
    "#### Exercise 8:  \n",
    "\n",
    "Evaluate feature importance by extracting the weights of the linear layer and creating a DataFrame to display the importance of each feature. Visualize the feature importance using a bar plot.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the weights of the linear layer\n",
    "## Write your code here\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "## Write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the Hint\n",
    "<!-- \n",
    "#Use the following code to extract the weight and create dataframe\n",
    "#Change the name of variables per your code\n",
    "\n",
    "Extract the weights of the linear layer:\n",
    "weights = model.linear.weight.data.numpy().flatten()\n",
    "features = X.columns\n",
    "Create a DataFrame for feature importance:\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Importance': weights})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance)\n",
    "Plot feature importance plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:  \n",
    "\n",
    "Congratulations on completing the project! In this final project, you built a logistic regression model to predict the outcomes of League of Legends matches based on various in-game statistics. This comprehensive project involved several key steps, including data loading and preprocessing, model implementation, training, optimization, evaluation, visualization, model saving and loading, hyperparameter tuning, and feature importance analysis. This project provided hands-on experience with the complete workflow of developing a machine learning model for binary classification tasks using PyTorch.\n",
    "\n",
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "3954a6768947e1337f1fbb623d47144c102fda57b5eb30076fea611e015e66ea"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
